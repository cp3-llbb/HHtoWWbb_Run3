[batch]
backend = htcondor

[htcondor]
jobflavour = "longlunch"

[das]
sitename = T2_CH_CERN
storageroot = /eos/cms
xrootdredirector = cms-xrd-global.cern.ch

[dask_condor]
adapt_max = 100
partitions_per_file = 4

[dask_local]
n_workers = 4
threads_per_worker = 1
partitions_per_file = 10

[spark]
adapt_max = 100 ; submit max. 100 jobs
partitions_per_file = 4 ; split each file into 4 chunks
